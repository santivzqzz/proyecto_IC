En primer lugar tenemos el programa que genera la clase miThread (miThread.py):

	De los módulos que necesitamos sólo importamos lo que usamos para no gastar tanto tiempo en importando el resto.

	Definimos una clase llamada miThread que hereda de Thread. Recibe un argumento, que es el número de repeticiones, cuando se inicia la clase. Lo hacemos de esta manera porque el argumento va cambiando de valor para tener en cuenta el resto de la división entre un millón y el número de hilos. Este cálculo se hace con el cociente (c), el resto (r) y el número de repeticiones (nr). Nos aseguramos de repartir el resto para que las distintas repeticiones con distinto número de hilos hagan siempre un millón de iteraciones y no menos. Este cálculo está en PDP11.py y así eliminamos un pequeño error.

	El cálculo intensivo es la raíz cúbica de aplicar la tangente y la arcotangente 5 veces a 123456789.123456789. Cada hilo hace este cálculo nr veces. Usamos el módulo math por su diferencia de tiempo con el de numpy. Math tardaba menos de 1 segundo en hacer el cálculo intensivo sin hilos un millón de veces y numpy tardaba 9 segundos. La raíz cúbica la hacemos elevando a un tercio porque es lo más rápido. Probamos a hacer la raíz cúbica de 123456789.123456789 cien millones de veces. Con cbrt de numpy tardó 53.54 segundos, con elevar a un tercio en numpy (power) tardó 107.83 segundos, con pow de python tardó 11.45 segundos y elevando con ** tardó 3.78 segundos. Entonces elegimos **.
	
	En el programa hay prints que están comentados que enseñarían en que momento del hilo estamos: en su inicio, en su ejecución o en tras su final. En el inicio podemos ver que todos los hilos se ejecutan en orden de creación, pero acaban en orden en desorden dependiendo de lo que haya hecho el sistema operativo. Poner el print de durante la ejecución hace que se relentice mucho el programa, no sirve demasiado demasiado porque hay un millón de ellos y el texto pasa muy rápido para leerlos.

En segundo lugar tenemos el código en python de cálculo intensivo (PDP11.py):

	De los módulos que necesitamos sólo importamos lo que usamos para no gastar tanto tiempo en importando el resto.
	
	Importamos la clase miThread del archivo miThread.py.

	Este código recibe como argumento el número de hilos con el módulo sys. Como el primer elemento de argv es el nombre del programa cogemos el segundo elemento en una condicional cuando hay más de un argumento.
	
	Medimos el tiempo en nanosegundos para tener más precisión.
	
	Todos los hilos con distinto número de repeticiones se meten en una lista llamada hilos mediante un bucle. En el bucle repartimos el resto de la división entre los distintos hilos y tenemos un print comentado que enseñaría cuando se ha creado cada hilo. Los hilos se crean por orden.
		
	Se guarda el tiempo antes de iniciar los hilos en un bucle con .start() y se espera a su ejecución con un bucle con .join() y se mide el final. Se imprime la diferencia entre el final y el incio porque esta es la manera de recibirlo que tiene Colector.sh el archivo de bash.
	
En tercer lugar tenemos la carpeta __pycache__:

	Esta carpeta se crea automáticamente cuando se importa un archivo de python. Esto ocurre cuando importamos miThread.py a PDP11.py. Hace que se importe más rápido la siguiente vez.

En cuarto lugar tenemos el código en bash que recoge y guarda los datos (Colector.sh):

	Primero eliminamos el archivo times.txt que es el que guarda los tiempos y el nombre.

	Buscamos el nombre único del modelo del núcleo y lo guarda en times.txt recortado.
	
	El programa está en un bucle de 5 repeticiones para hacer la media de las repeticiones para compensar la posible anomalía de algún tiempo.
	
	El segundo bucle le va pasando el valor de k a PDP11.py que es el número de hilos. El tiempo que devuelve PDP11.py se añade a la lista de tiempos con una coma. Cada lista de tiempos se formatea para que haya una coma entre elementos y no haya una al final. Se añade a una nueva linea del archivo times.txt y el array times se vacía. El programa también enseña el tiempo con el número hilos y en cual de las cinco iteraciones está.
	
Finalmente tenemos el creador de la gráfica (Grafica.py):

	Primero sacamos la primera línea de times.txt que es el nombre del modelo. Después pone en una lista los tiempos que saca de times.txt, los convierte a float y elimina los espacios en blanco que aparecen en el programa en bash.
	
	En segundo lugar cuenta la longitud mínima de las listas de dentro de tiempos y recorta el resto para que midan lo mismo.
	
	En tercer lugar hace la media para los tiempos de cada número de hilos para compensar los posibles errores.
	
	Finalmente, se representa la gráfica transformando los tiempos a segundos enseñando la media y cada una de las cinco pruebas. Además también guarda la grafica con el nombre del núcleo.
	
Ahora analizaremos los resultados de la gráfica:

	El sistema operativo decide qué hacer con los hilos. Supuestamente el mínimo debería ser el número de núcleos que tiene el equipo por el número de hilos en paralelo que permite cada núcleo. Desde un hilo hasta ese número descendería la gráfica y a partir de ese punto subiría. Esto sería en un caso perfecto.
	
	Pero el sistema operativo hace lo que quiere con los hilos. En algunos equipos que probamos no ocurría el caso anterior. El mejor tiempo era con un sólo hilo y después el segundo era más y a partir de ahí una linea recta. El sistema operativo igual decide tener todos los hilos trabajando en el mismo núcleo. Esto se podría controlar porgramando para que cada hilo se mandase a un núcleo distinto pero no lo hacemos.
